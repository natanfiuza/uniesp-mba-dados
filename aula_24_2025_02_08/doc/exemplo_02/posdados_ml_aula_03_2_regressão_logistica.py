# -*- coding: utf-8 -*-
"""PosDados_ML - Aula 03.2 - Regressão Logistica.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vKF79lR1sIrWVR5SnLQFh-GNrDTrWyWv

# **Importação dos dados**
"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

import numpy as np
import pandas as pd

import seaborn as sns
from matplotlib import pyplot as plt

# Url do arquivo: https://raw.githubusercontent.com/mrafaelbatista/uniesp_mba_machine_learning/refs/heads/main/classwork/credit.csv
credit_df = pd.read_csv('credit.csv')
credit_df.head()

credit_df.columns

credit_df.Risk.value_counts()

"""
### **-- Precisamos preprocessar os dados -- Tarefa de vcs!!**"""

credit_df['Risk_Num'] = np.where(credit_df['Risk']=='good', 1, 0)
credit_df.Risk_Num.value_counts()

# Cria classe nova para NAs
credit_df=credit_df.fillna('Null')

credit_df.head()

# Entendendo as variaveis categoricas
print(credit_df['Job'].value_counts())
print(credit_df['Housing'].value_counts())
print(credit_df['Saving accounts'].value_counts())
print(credit_df['Checking account'].value_counts())
print(credit_df['Purpose'].value_counts())

# Converte as variaveis categoricas em dummies
credit_df=pd.get_dummies(credit_df)

credit_df.head()

# As variaveis numericas nao sao convertidas, entao
# vamos primeiro criar um df com as dummies dela, depois adicionamos ao nosso df original
dummy_job = pd.get_dummies(credit_df['Job'])
dummy_job = dummy_job.rename(columns={0: "Job 0", 1: "Job 1", 2: "Job 2", 3: "Job 3"})
dummy_job.head()

# Passa as variaveis Job para nossa base
credit_df["Job_0"] = dummy_job["Job 0"]
credit_df["Job_1"] = dummy_job["Job 1"]
credit_df["Job_2"] = dummy_job["Job 2"]
credit_df["Job_3"] = dummy_job["Job 3"]
credit_df.head()

"""## **Segmentando a amostra**"""

metrics = ['Age','Sex_female','Job_0','Job_1','Job_2','Credit amount','Duration','Housing_free','Housing_own','Saving accounts_Null','Saving accounts_little','Saving accounts_moderate','Saving accounts_quite rich','Checking account_Null','Checking account_little','Checking account_moderate','Purpose_business','Purpose_car','Purpose_domestic appliances','Purpose_education','Purpose_furniture/equipment','Purpose_radio/TV','Purpose_repairs']
x = credit_df[metrics]
x.head()

outcome = ["Risk_Num"]
y = credit_df[outcome]
y.head()

X_train, X_test, y_train, y_test = train_test_split(
    x, y, test_size =0.30, stratify=y)
print(X_train.shape)
print(X_test.shape)

credit_df.corr()

credit_df

"""### **Regressão Logística**"""

lr = LogisticRegression(random_state=42, solver='lbfgs')

#treino do modelo
lr.fit(X_train, y_train)

y_pred = lr.predict(X_test)
y_pred

from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_pred)

"""### **Respondendo às perguntas**"""

'''
Age
Sex_female
Job_0	Job_1	Job_2
Credit amount
Duration
Housing_free	Housing_own
Saving accounts_Null Saving accounts_little	Saving accounts_moderate	Saving accounts_quite rich
Checking account_Null	Checking account_little	Checking account_moderate
Purpose_business	Purpose_car	Purpose_domestic appliances	Purpose_education	Purpose_furniture/equipment	Purpose_radio/TV	Purpose_repairs


Id,Age,Sex,Job,Housing,Saving accounts,Checking account,Credit amount,Duration,Purpose,Risk
1 - Cliente A - Gertrude Rocha
1001, 60, female,2,own,quite rich,NA,2835,24,furniture/equipment,?

2 - Cliente B - Abelardo Jurema
1002, 53, male,1,own,little,NA,2835,36,furniture/equipment,?

3 - Cliente C - Sérgio
1003,20,male,2,free,moderate,moderate,5866,18,car,?

#23 colunas
1- 60,1, 0,0,1, 2835,24, 0,1, 0,0,0,1, 1,0,0, 0,0,0,0,1,0,0
2- 53,0, 0,1,0, 2835,36, 0,1, 0,1,0,0, 1,0,0, 0,0,1,0,0,0,0
3- 20,0, 0,0,1, 5866,18, 1,0, 0,0,1,0, 0,0,1, 0,1,0,0,0,0,0
'''

cliente1 = [60,1, 0,0,1, 2835,24, 0,1, 0,0,0,1, 1,0,0, 0,0,0,0,1,0,0]
cliente2 = [53,0, 0,1,0, 2835,36, 0,1, 0,1,0,0, 1,0,0, 0,0,1,0,0,0,0]
cliente3 = [20,0, 0,0,1, 5866,18, 1,0, 0,0,1,0, 0,0,1, 0,1,0,0,0,0,0]

clientesAnalise = [cliente1, cliente2, cliente3]

respostas = lr.predict(clientesAnalise)
respostas #1: good e 0:bad