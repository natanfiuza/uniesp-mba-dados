# -*- coding: utf-8 -*-
"""PosDados_ML - Aula 03.2 - Regressão Linear.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A7ydEXlDjGqoaEXc4BtZt-gKTWTwGhA6

## **Preparando os Dados**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from math import sqrt

from yellowbrick.regressor import PredictionError
from yellowbrick.regressor import ResidualsPlot

dados_original = pd.read_csv('dadosHab.csv')
dados_original.head()

"""## **Avaliando as correlações**"""

dados_original.corr()

dados_original.describe()

"""## **Segmentando a amostra e teste - Apenas uma variável independente**"""

metricas = ["Area"] # (VALOR) = a(AREA) + b
x = dados_original[metricas]
x.head()

saida = ["Valor"]
y = dados_original[saida]
y.head()

treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, test_size =0.30)
print(treino_x.shape)
input("\nPressione enter para continuar...\n")
print(teste_x.shape)
input("\nPressione enter para continuar...\n")
print("Treinaremos com %d elementos e testaremos com %d elementos" % (len(treino_x), len(teste_x)))
input("\nPressione enter para continuar...\n")
"""# **Regressão Linear Simples**

## **Regressão Linear Simple com Sklearn**
"""

ax = sns.scatterplot(x=treino_y['Valor'], y=treino_x['Area'])

ax.set_title('Dados dispersos')
ax.set_xlabel('Área')
ax.set_ylabel('Valor')
plt.show()
print("Exibição de dadps dispersos 1")
input("\nPressione enter para continuar...\n")
valor = np.log(treino_y['Valor'])
area = np.log(treino_x['Area'])

ax = sns.scatterplot(x=area, y=valor)

ax.set_title('Dados dispersos')
ax.set_xlabel('Área')
ax.set_ylabel('Valor')
plt.show()
print("Exibição de dadps dispersos 2")
input("\nPressione enter para continuar...\n")

"""### **Construção do Modelo**"""

############################
## Modelo do sk-learn¶

lr = LinearRegression()

#Treinamento

lr.fit(np.array(area).reshape(len(area), 1), valor)

#Ponto de interceptação em y
print(lr.intercept_)

input("\nPressione enter para continuar...\n")

#coeficiente ou inclinação
print(lr.coef_)
input("\nPressione enter para continuar...\n")
"""### **Validação - Teste**"""

test_pred = lr.predict(teste_x)
test_pred

areaConhecida = np.log(100)
valorDesconhecido = lr.predict([[areaConhecida]])
np.exp(valorDesconhecido) #mostrar o valor real

r2_score(teste_y, test_pred)

rmse = sqrt(mean_squared_error(teste_y, test_pred))
print("\nrmse\n")
print(rmse)
input("\nPressione enter para continuar...\n")

mae = mean_absolute_error(teste_y, test_pred)
print("\nmean_absolute_error\n")
print(mae)
input("\nPressione enter para continuar...\n")

"""### **Visualização Gráfica**"""

x1 = np.log(x)
y1 = np.log(y)

X_train, X_test, y_train, y_test = train_test_split(
    x1, y1, test_size=0.3, random_state=42)

model = Ridge()
visualizer = ResidualsPlot(model)

visualizer.fit(np.array(X_train), np.array(y_train))  # Fit the training data to the visualizer
visualizer.score(np.array(X_test), np.array(y_test))  # Evaluate the model on the test data

"""Um uso comum do gráfico de resíduos é analisar a variação do erro do regressor. Se os pontos são dispersos aleatoriamente ao redor do eixo horizontal, um modelo de regressão linear é geralmente apropriado para os dados; caso contrário, um modelo não linear é mais apropriado. No caso acima, vemos uma distribuição uniforme e aleatória dos resíduos em relação ao alvo em duas dimensões. Isso parece indicar que nosso modelo linear está funcionando bem. Também podemos ver no histograma que nosso erro é normalmente distribuído em torno de zero, o que geralmente também indica um modelo bem ajustado."""

###Visualizando nossos resultados de forma gráfica
#Usando os dados de teste

#Transformacao das entradas
valor_ = np.array(np.log(teste_y['Valor']))
area_ = np.array(np.log(teste_x['Area']))

ax = sns.scatterplot(x=area_, y=valor_)

model = LinearRegression()
model.fit(np.array(area_).reshape(len(area_),1), valor_)

y_p = model.predict(np.array(area_).reshape(len(area_),1))

ax = sns.lineplot(x=area_,y = y_p, color = 'red')

ax.set_title('Curva prevista nos dados dispersos')
ax.set_xlabel('Área')
ax.set_ylabel('Valor previsto com nosso modelo')
plt.show()
print('Curva prevista nos dados dispersos')
input("\nPressione enter para continuar...\n")
residuo = valor_ - y_p

ax = sns.distplot(residuo) #residuo = y_train - y_previsto_train
ax.figure.set_size_inches(12, 6)
ax.set_title('Distribuição dos valores residuais', fontsize=18)
ax.set_xlabel('Log (Preço)', fontsize=14)
ax.set_ylabel('Densidade', fontsize=14)
plt.show()
print("Distribuição dos valores residuais")
input("\nPressione enter para continuar...\n")

"""# **Regressão Linear Múltipla**

## **Método 1 - Com o sklearn**
"""

########################
## Regressão multivariável

dados_original = pd.read_csv('https://raw.githubusercontent.com/mrafaelbatista/uniesp-mba-dados-machine-learning/master/db/dadosHab.csv')
dados_original.head()

#Reajustando as amostras de teste e treino

metricas = ["Area","Dist_Praia","Dist_Farmacia"]
x = dados_original[metricas]

saida = ["Valor"]
y = dados_original[saida]

"""### **Segmentação da amostra - treino e teste**"""

treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, test_size =0.3, random_state=42)

#treino , teste = train_test_split(x, y, test_size =0.3, random_state=42)

"""### **Criação e Treinamento do Modelo**"""

lr = LinearRegression()

lr.fit(treino_x, treino_y)

#Ponto de interceptação em y
print(lr.intercept_)

#Inclinação
print(lr.coef_)

"""### **Etapa de Teste do Modelo**"""

imovel = [[200, 0.25, 0.80]]
ValorPrevisto = lr.predict(imovel)
ValorPrevisto

valor_p = lr.predict(teste_x)

"""### **Avaliação do Modelo**"""

r2_score(y, lr.predict(x))

rmse = sqrt(mean_squared_error(teste_y, test_pred))
print(rmse)

mae = mean_absolute_error(teste_y, test_pred)
print(mae)

residuo = teste_y - valor_p #residuo = y_train - y_previsto_train

ax = sns.distplot(residuo)
ax.figure.set_size_inches(12, 6)
ax.set_title('Distribuição dos valores residuais', fontsize=18)
ax.set_xlabel('Log (Preço)', fontsize=14)
ax.set_ylabel('Densidade', fontsize=14)
plt.show()